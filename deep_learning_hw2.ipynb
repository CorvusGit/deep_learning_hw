{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0290730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ac3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf06b7",
   "metadata": {},
   "source": [
    "# Получаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1981dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09a8e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015231d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba17478f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_dataset.targets.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c75fd8",
   "metadata": {},
   "source": [
    "# Подбираем архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9680f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epochs):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "            \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, time.time() - start, round(train_loss / train_iters,5), round(train_acc / train_passed,5),\n",
    "            round(test_loss / test_iters,5), round(test_acc / test_passed,5))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99aaf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_n = 784\n",
    "out_n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475e7aa",
   "metadata": {},
   "source": [
    "### Базовая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3322f3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_n,512 ),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512,128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, out_n)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ea136eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c142d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 9.275, train_loss: 0.57253, train_acc: 0.79198, test_loss: 0.42299, test_acc: 0.8431\n",
      "ep: 1, taked: 9.172, train_loss: 0.38478, train_acc: 0.85907, test_loss: 0.39612, test_acc: 0.8553\n",
      "ep: 2, taked: 9.191, train_loss: 0.35127, train_acc: 0.87105, test_loss: 0.37073, test_acc: 0.8659\n",
      "ep: 3, taked: 9.246, train_loss: 0.33069, train_acc: 0.87663, test_loss: 0.3724, test_acc: 0.8664\n",
      "ep: 4, taked: 9.239, train_loss: 0.31377, train_acc: 0.88293, test_loss: 0.38656, test_acc: 0.8639\n",
      "ep: 5, taked: 9.255, train_loss: 0.30801, train_acc: 0.8868, test_loss: 0.39395, test_acc: 0.8614\n",
      "ep: 6, taked: 9.218, train_loss: 0.29933, train_acc: 0.8886, test_loss: 0.41387, test_acc: 0.8625\n",
      "ep: 7, taked: 9.281, train_loss: 0.2906, train_acc: 0.8921, test_loss: 0.37779, test_acc: 0.8693\n",
      "ep: 8, taked: 9.242, train_loss: 0.28328, train_acc: 0.89338, test_loss: 0.4014, test_acc: 0.8674\n",
      "ep: 9, taked: 9.240, train_loss: 0.27676, train_acc: 0.8964, test_loss: 0.37143, test_acc: 0.8718\n",
      "ep: 10, taked: 9.209, train_loss: 0.27117, train_acc: 0.89853, test_loss: 0.37416, test_acc: 0.8715\n",
      "ep: 11, taked: 9.208, train_loss: 0.26763, train_acc: 0.89975, test_loss: 0.36268, test_acc: 0.8771\n",
      "ep: 12, taked: 9.198, train_loss: 0.2648, train_acc: 0.90043, test_loss: 0.38621, test_acc: 0.8714\n",
      "ep: 13, taked: 9.210, train_loss: 0.25598, train_acc: 0.90302, test_loss: 0.39408, test_acc: 0.8724\n",
      "ep: 14, taked: 9.198, train_loss: 0.25987, train_acc: 0.90295, test_loss: 0.38769, test_acc: 0.8751\n",
      "ep: 15, taked: 9.220, train_loss: 0.25418, train_acc: 0.90432, test_loss: 0.38809, test_acc: 0.8747\n",
      "ep: 16, taked: 9.194, train_loss: 0.24876, train_acc: 0.90487, test_loss: 0.43729, test_acc: 0.8689\n",
      "ep: 17, taked: 9.226, train_loss: 0.24693, train_acc: 0.9069, test_loss: 0.39421, test_acc: 0.8736\n",
      "ep: 18, taked: 9.223, train_loss: 0.24726, train_acc: 0.90658, test_loss: 0.40595, test_acc: 0.8668\n",
      "ep: 19, taked: 9.267, train_loss: 0.2427, train_acc: 0.90858, test_loss: 0.40762, test_acc: 0.8732\n",
      "ep: 20, taked: 9.175, train_loss: 0.235, train_acc: 0.91007, test_loss: 0.39467, test_acc: 0.8746\n",
      "ep: 21, taked: 9.219, train_loss: 0.23964, train_acc: 0.91028, test_loss: 0.40708, test_acc: 0.8758\n",
      "ep: 22, taked: 9.193, train_loss: 0.23298, train_acc: 0.91088, test_loss: 0.40551, test_acc: 0.868\n",
      "ep: 23, taked: 9.262, train_loss: 0.23908, train_acc: 0.91015, test_loss: 0.40795, test_acc: 0.8728\n",
      "ep: 24, taked: 9.221, train_loss: 0.23502, train_acc: 0.9118, test_loss: 0.43845, test_acc: 0.8693\n",
      "ep: 25, taked: 9.222, train_loss: 0.23486, train_acc: 0.91112, test_loss: 0.39897, test_acc: 0.8727\n",
      "ep: 26, taked: 9.241, train_loss: 0.22843, train_acc: 0.91363, test_loss: 0.41324, test_acc: 0.87\n",
      "ep: 27, taked: 9.278, train_loss: 0.22784, train_acc: 0.91493, test_loss: 0.40321, test_acc: 0.8735\n",
      "ep: 28, taked: 9.227, train_loss: 0.22952, train_acc: 0.91355, test_loss: 0.43812, test_acc: 0.8651\n",
      "ep: 29, taked: 9.195, train_loss: 0.23016, train_acc: 0.91353, test_loss: 0.45895, test_acc: 0.8674\n",
      "ep: 30, taked: 9.220, train_loss: 0.22614, train_acc: 0.91527, test_loss: 0.44513, test_acc: 0.868\n",
      "ep: 31, taked: 9.237, train_loss: 0.21834, train_acc: 0.91603, test_loss: 0.4317, test_acc: 0.8634\n",
      "ep: 32, taked: 9.360, train_loss: 0.21956, train_acc: 0.9175, test_loss: 0.43195, test_acc: 0.8715\n",
      "ep: 33, taked: 9.223, train_loss: 0.22684, train_acc: 0.91525, test_loss: 0.4382, test_acc: 0.8757\n",
      "ep: 34, taked: 9.211, train_loss: 0.21906, train_acc: 0.91842, test_loss: 0.44544, test_acc: 0.876\n",
      "ep: 35, taked: 9.198, train_loss: 0.21405, train_acc: 0.91918, test_loss: 0.44332, test_acc: 0.8813\n",
      "ep: 36, taked: 9.197, train_loss: 0.21331, train_acc: 0.91897, test_loss: 0.50212, test_acc: 0.8749\n",
      "ep: 37, taked: 9.336, train_loss: 0.20759, train_acc: 0.92098, test_loss: 0.46099, test_acc: 0.873\n",
      "ep: 38, taked: 9.294, train_loss: 0.21093, train_acc: 0.92007, test_loss: 0.45941, test_acc: 0.8764\n",
      "ep: 39, taked: 9.209, train_loss: 0.21407, train_acc: 0.9204, test_loss: 0.46456, test_acc: 0.8683\n",
      "ep: 40, taked: 9.218, train_loss: 0.20803, train_acc: 0.9213, test_loss: 0.48238, test_acc: 0.8643\n",
      "ep: 41, taked: 9.253, train_loss: 0.20924, train_acc: 0.9227, test_loss: 0.5113, test_acc: 0.8709\n",
      "ep: 42, taked: 9.273, train_loss: 0.21481, train_acc: 0.92038, test_loss: 0.46848, test_acc: 0.8718\n",
      "ep: 43, taked: 9.252, train_loss: 0.20523, train_acc: 0.9228, test_loss: 0.49746, test_acc: 0.8744\n",
      "ep: 44, taked: 9.257, train_loss: 0.20079, train_acc: 0.92348, test_loss: 0.52123, test_acc: 0.8755\n",
      "ep: 45, taked: 9.267, train_loss: 0.20072, train_acc: 0.92438, test_loss: 0.50566, test_acc: 0.8674\n",
      "ep: 46, taked: 9.223, train_loss: 0.20921, train_acc: 0.92178, test_loss: 0.46854, test_acc: 0.8763\n",
      "ep: 47, taked: 9.300, train_loss: 0.1946, train_acc: 0.92727, test_loss: 0.5163, test_acc: 0.8759\n",
      "ep: 48, taked: 9.313, train_loss: 0.20509, train_acc: 0.92402, test_loss: 0.50582, test_acc: 0.8762\n",
      "ep: 49, taked: 9.399, train_loss: 0.19693, train_acc: 0.92608, test_loss: 0.51023, test_acc: 0.8779\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8b1a7",
   "metadata": {},
   "source": [
    "### Подбираем более удачную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce8d9a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=1024, out_features=384, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_n, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1024, 384),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(384, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, out_n)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8bc1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "812e4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 10.844, train_loss: 0.61744, train_acc: 0.7737, test_loss: 0.43491, test_acc: 0.8411\n",
      "ep: 1, taked: 10.611, train_loss: 0.42139, train_acc: 0.84552, test_loss: 0.40212, test_acc: 0.8515\n",
      "ep: 2, taked: 10.622, train_loss: 0.38524, train_acc: 0.85865, test_loss: 0.38647, test_acc: 0.8607\n",
      "ep: 3, taked: 10.637, train_loss: 0.3642, train_acc: 0.86577, test_loss: 0.37917, test_acc: 0.8632\n",
      "ep: 4, taked: 10.679, train_loss: 0.34623, train_acc: 0.87148, test_loss: 0.36235, test_acc: 0.8718\n",
      "ep: 5, taked: 10.668, train_loss: 0.33596, train_acc: 0.87558, test_loss: 0.3714, test_acc: 0.8678\n",
      "ep: 6, taked: 10.678, train_loss: 0.32474, train_acc: 0.87953, test_loss: 0.35782, test_acc: 0.87\n",
      "ep: 7, taked: 10.633, train_loss: 0.3163, train_acc: 0.88227, test_loss: 0.34164, test_acc: 0.8767\n",
      "ep: 8, taked: 10.631, train_loss: 0.30737, train_acc: 0.88575, test_loss: 0.33987, test_acc: 0.8787\n",
      "ep: 9, taked: 10.638, train_loss: 0.30218, train_acc: 0.8861, test_loss: 0.33943, test_acc: 0.879\n",
      "ep: 10, taked: 10.633, train_loss: 0.29789, train_acc: 0.88847, test_loss: 0.33137, test_acc: 0.8825\n",
      "ep: 11, taked: 10.635, train_loss: 0.28896, train_acc: 0.89143, test_loss: 0.3284, test_acc: 0.882\n",
      "ep: 12, taked: 10.641, train_loss: 0.28516, train_acc: 0.89238, test_loss: 0.33193, test_acc: 0.8827\n",
      "ep: 13, taked: 10.636, train_loss: 0.27996, train_acc: 0.89427, test_loss: 0.31546, test_acc: 0.8852\n",
      "ep: 14, taked: 10.697, train_loss: 0.27556, train_acc: 0.89657, test_loss: 0.30786, test_acc: 0.8862\n",
      "ep: 15, taked: 10.703, train_loss: 0.27095, train_acc: 0.89718, test_loss: 0.30378, test_acc: 0.8893\n",
      "ep: 16, taked: 10.685, train_loss: 0.26445, train_acc: 0.89842, test_loss: 0.31001, test_acc: 0.8871\n",
      "ep: 17, taked: 10.708, train_loss: 0.26059, train_acc: 0.90038, test_loss: 0.30578, test_acc: 0.8882\n",
      "ep: 18, taked: 10.636, train_loss: 0.25731, train_acc: 0.90202, test_loss: 0.30962, test_acc: 0.8888\n",
      "ep: 19, taked: 10.648, train_loss: 0.25509, train_acc: 0.90362, test_loss: 0.31323, test_acc: 0.8875\n",
      "ep: 20, taked: 10.606, train_loss: 0.25257, train_acc: 0.90377, test_loss: 0.29777, test_acc: 0.8914\n",
      "ep: 21, taked: 10.661, train_loss: 0.24535, train_acc: 0.90655, test_loss: 0.30765, test_acc: 0.8882\n",
      "ep: 22, taked: 10.645, train_loss: 0.24215, train_acc: 0.90682, test_loss: 0.30349, test_acc: 0.8925\n",
      "ep: 23, taked: 10.652, train_loss: 0.24078, train_acc: 0.90817, test_loss: 0.30064, test_acc: 0.8946\n",
      "ep: 24, taked: 10.673, train_loss: 0.23472, train_acc: 0.91095, test_loss: 0.29719, test_acc: 0.8928\n",
      "ep: 25, taked: 10.605, train_loss: 0.23633, train_acc: 0.90937, test_loss: 0.30347, test_acc: 0.8909\n",
      "ep: 26, taked: 10.607, train_loss: 0.23335, train_acc: 0.91025, test_loss: 0.3003, test_acc: 0.8942\n",
      "ep: 27, taked: 10.631, train_loss: 0.22984, train_acc: 0.91183, test_loss: 0.30332, test_acc: 0.8921\n",
      "ep: 28, taked: 10.643, train_loss: 0.2271, train_acc: 0.91182, test_loss: 0.29966, test_acc: 0.8934\n",
      "ep: 29, taked: 10.632, train_loss: 0.22187, train_acc: 0.91415, test_loss: 0.30591, test_acc: 0.8944\n",
      "ep: 30, taked: 10.638, train_loss: 0.22088, train_acc: 0.91527, test_loss: 0.29842, test_acc: 0.896\n",
      "ep: 31, taked: 10.618, train_loss: 0.22066, train_acc: 0.91562, test_loss: 0.29986, test_acc: 0.8972\n",
      "ep: 32, taked: 10.666, train_loss: 0.21902, train_acc: 0.91573, test_loss: 0.29952, test_acc: 0.8934\n",
      "ep: 33, taked: 10.638, train_loss: 0.21679, train_acc: 0.91643, test_loss: 0.30209, test_acc: 0.8962\n",
      "ep: 34, taked: 10.650, train_loss: 0.21222, train_acc: 0.9183, test_loss: 0.30876, test_acc: 0.8959\n",
      "ep: 35, taked: 10.638, train_loss: 0.21241, train_acc: 0.9171, test_loss: 0.29759, test_acc: 0.897\n",
      "ep: 36, taked: 10.657, train_loss: 0.20865, train_acc: 0.91853, test_loss: 0.3047, test_acc: 0.8959\n",
      "ep: 37, taked: 10.651, train_loss: 0.20819, train_acc: 0.91973, test_loss: 0.30281, test_acc: 0.8971\n",
      "ep: 38, taked: 10.740, train_loss: 0.20435, train_acc: 0.92057, test_loss: 0.29839, test_acc: 0.8964\n",
      "ep: 39, taked: 10.842, train_loss: 0.20109, train_acc: 0.92213, test_loss: 0.30946, test_acc: 0.8944\n",
      "ep: 40, taked: 10.893, train_loss: 0.19827, train_acc: 0.92425, test_loss: 0.29899, test_acc: 0.9\n",
      "ep: 41, taked: 10.716, train_loss: 0.19576, train_acc: 0.9239, test_loss: 0.31718, test_acc: 0.8971\n",
      "ep: 42, taked: 10.627, train_loss: 0.19581, train_acc: 0.92423, test_loss: 0.30655, test_acc: 0.8979\n",
      "ep: 43, taked: 10.620, train_loss: 0.19826, train_acc: 0.9236, test_loss: 0.31023, test_acc: 0.8958\n",
      "ep: 44, taked: 10.592, train_loss: 0.19306, train_acc: 0.92592, test_loss: 0.30964, test_acc: 0.8977\n",
      "ep: 45, taked: 10.648, train_loss: 0.19068, train_acc: 0.92607, test_loss: 0.30654, test_acc: 0.898\n",
      "ep: 46, taked: 10.846, train_loss: 0.18851, train_acc: 0.92647, test_loss: 0.30667, test_acc: 0.8945\n",
      "ep: 47, taked: 10.677, train_loss: 0.18933, train_acc: 0.92632, test_loss: 0.30809, test_acc: 0.897\n",
      "ep: 48, taked: 10.683, train_loss: 0.18836, train_acc: 0.92768, test_loss: 0.31243, test_acc: 0.8965\n",
      "ep: 49, taked: 10.577, train_loss: 0.18387, train_acc: 0.92793, test_loss: 0.29661, test_acc: 0.8979\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84aafa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 12.457, train_loss: 0.76822, train_acc: 0.70563, test_loss: 0.46077, test_acc: 0.8282\n",
      "ep: 1, taked: 12.459, train_loss: 0.47878, train_acc: 0.82898, test_loss: 0.41312, test_acc: 0.8492\n",
      "ep: 2, taked: 12.385, train_loss: 0.43757, train_acc: 0.84268, test_loss: 0.4025, test_acc: 0.853\n",
      "ep: 3, taked: 12.484, train_loss: 0.41736, train_acc: 0.8519, test_loss: 0.39951, test_acc: 0.8586\n",
      "ep: 4, taked: 12.434, train_loss: 0.39692, train_acc: 0.85658, test_loss: 0.37584, test_acc: 0.8634\n",
      "ep: 5, taked: 12.434, train_loss: 0.38612, train_acc: 0.86085, test_loss: 0.36253, test_acc: 0.8701\n",
      "ep: 6, taked: 12.456, train_loss: 0.37625, train_acc: 0.86433, test_loss: 0.35842, test_acc: 0.8676\n",
      "ep: 7, taked: 12.441, train_loss: 0.37045, train_acc: 0.86775, test_loss: 0.35426, test_acc: 0.8714\n",
      "ep: 8, taked: 12.475, train_loss: 0.36381, train_acc: 0.86885, test_loss: 0.35653, test_acc: 0.873\n",
      "ep: 9, taked: 12.453, train_loss: 0.35678, train_acc: 0.87143, test_loss: 0.34126, test_acc: 0.8767\n",
      "ep: 10, taked: 12.566, train_loss: 0.35252, train_acc: 0.87422, test_loss: 0.34223, test_acc: 0.8748\n",
      "ep: 11, taked: 12.454, train_loss: 0.34466, train_acc: 0.87715, test_loss: 0.34371, test_acc: 0.8715\n",
      "ep: 12, taked: 12.458, train_loss: 0.34453, train_acc: 0.87637, test_loss: 0.34173, test_acc: 0.8757\n",
      "ep: 13, taked: 12.379, train_loss: 0.33624, train_acc: 0.87683, test_loss: 0.33912, test_acc: 0.8763\n",
      "ep: 14, taked: 12.504, train_loss: 0.33306, train_acc: 0.87988, test_loss: 0.33439, test_acc: 0.8771\n",
      "ep: 15, taked: 12.706, train_loss: 0.3296, train_acc: 0.8813, test_loss: 0.32914, test_acc: 0.8816\n",
      "ep: 16, taked: 12.548, train_loss: 0.32374, train_acc: 0.88322, test_loss: 0.33391, test_acc: 0.8808\n",
      "ep: 17, taked: 12.554, train_loss: 0.32344, train_acc: 0.88217, test_loss: 0.32686, test_acc: 0.8798\n",
      "ep: 18, taked: 12.470, train_loss: 0.31998, train_acc: 0.88572, test_loss: 0.33426, test_acc: 0.8806\n",
      "ep: 19, taked: 12.379, train_loss: 0.31943, train_acc: 0.885, test_loss: 0.32356, test_acc: 0.8833\n",
      "ep: 20, taked: 12.502, train_loss: 0.31922, train_acc: 0.88432, test_loss: 0.3215, test_acc: 0.8859\n",
      "ep: 21, taked: 12.277, train_loss: 0.31622, train_acc: 0.8856, test_loss: 0.32758, test_acc: 0.8831\n",
      "ep: 22, taked: 12.466, train_loss: 0.30796, train_acc: 0.88785, test_loss: 0.3277, test_acc: 0.883\n",
      "ep: 23, taked: 12.449, train_loss: 0.3102, train_acc: 0.88762, test_loss: 0.32527, test_acc: 0.8834\n",
      "ep: 24, taked: 12.436, train_loss: 0.30281, train_acc: 0.8894, test_loss: 0.31839, test_acc: 0.8844\n",
      "ep: 25, taked: 12.460, train_loss: 0.3051, train_acc: 0.88988, test_loss: 0.32235, test_acc: 0.8843\n",
      "ep: 26, taked: 12.377, train_loss: 0.30367, train_acc: 0.88967, test_loss: 0.31767, test_acc: 0.8873\n",
      "ep: 27, taked: 12.519, train_loss: 0.29988, train_acc: 0.892, test_loss: 0.32001, test_acc: 0.8834\n",
      "ep: 28, taked: 12.396, train_loss: 0.30493, train_acc: 0.88933, test_loss: 0.31471, test_acc: 0.8861\n",
      "ep: 29, taked: 12.443, train_loss: 0.29948, train_acc: 0.89142, test_loss: 0.31741, test_acc: 0.8834\n",
      "ep: 30, taked: 12.293, train_loss: 0.297, train_acc: 0.89168, test_loss: 0.31965, test_acc: 0.8852\n",
      "ep: 31, taked: 12.361, train_loss: 0.29137, train_acc: 0.8938, test_loss: 0.31572, test_acc: 0.8849\n",
      "ep: 32, taked: 12.370, train_loss: 0.29292, train_acc: 0.89377, test_loss: 0.31639, test_acc: 0.8861\n",
      "ep: 33, taked: 12.571, train_loss: 0.29121, train_acc: 0.89528, test_loss: 0.31137, test_acc: 0.8849\n",
      "ep: 34, taked: 12.588, train_loss: 0.29615, train_acc: 0.89402, test_loss: 0.30754, test_acc: 0.8889\n",
      "ep: 35, taked: 12.421, train_loss: 0.2865, train_acc: 0.89605, test_loss: 0.30822, test_acc: 0.889\n",
      "ep: 36, taked: 12.490, train_loss: 0.28898, train_acc: 0.89658, test_loss: 0.31156, test_acc: 0.8902\n",
      "ep: 37, taked: 12.465, train_loss: 0.28712, train_acc: 0.89522, test_loss: 0.3072, test_acc: 0.8925\n",
      "ep: 38, taked: 12.379, train_loss: 0.28301, train_acc: 0.89717, test_loss: 0.31043, test_acc: 0.8869\n",
      "ep: 39, taked: 12.439, train_loss: 0.2845, train_acc: 0.89695, test_loss: 0.30967, test_acc: 0.8905\n",
      "ep: 40, taked: 12.457, train_loss: 0.28291, train_acc: 0.89785, test_loss: 0.31145, test_acc: 0.8866\n",
      "ep: 41, taked: 12.488, train_loss: 0.28084, train_acc: 0.89908, test_loss: 0.30991, test_acc: 0.8857\n",
      "ep: 42, taked: 12.470, train_loss: 0.27823, train_acc: 0.89913, test_loss: 0.30474, test_acc: 0.8897\n",
      "ep: 43, taked: 12.433, train_loss: 0.28415, train_acc: 0.89782, test_loss: 0.31054, test_acc: 0.8895\n",
      "ep: 44, taked: 12.514, train_loss: 0.28018, train_acc: 0.89967, test_loss: 0.30253, test_acc: 0.8941\n",
      "ep: 45, taked: 12.491, train_loss: 0.27841, train_acc: 0.90033, test_loss: 0.30905, test_acc: 0.891\n",
      "ep: 46, taked: 12.432, train_loss: 0.27552, train_acc: 0.90105, test_loss: 0.30214, test_acc: 0.8911\n",
      "ep: 47, taked: 12.511, train_loss: 0.27207, train_acc: 0.9013, test_loss: 0.30714, test_acc: 0.8897\n",
      "ep: 48, taked: 12.529, train_loss: 0.27672, train_acc: 0.90167, test_loss: 0.3069, test_acc: 0.8872\n",
      "ep: 49, taked: 12.397, train_loss: 0.27199, train_acc: 0.9004, test_loss: 0.30971, test_acc: 0.8909\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_n, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(512, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(512, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(512, out_n)\n",
    ")\n",
    "model\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ed4fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no batch test result: 0.8727\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40501d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
