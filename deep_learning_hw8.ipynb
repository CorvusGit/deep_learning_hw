{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e2580dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "503f648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\RK\\rus-eng\\rus.txt\",sep='\\t',names=['eng','rus','c'],encoding='utf-8')[['eng','rus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "953a05e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>rus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Марш!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Иди.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Идите.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Здравствуйте.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Привет!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496054</th>\n",
       "      <td>At a moment when our economy is growing, our b...</td>\n",
       "      <td>В тот момент, когда наша экономика растёт, наш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496055</th>\n",
       "      <td>When I was younger, I hated going to weddings....</td>\n",
       "      <td>Когда я была помоложе, я ненавидела ходить на ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496056</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Поскольку сайтов, посвящённых какой-либо теме,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496057</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Если кто-то незнакомый говорит, что вы говорит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496058</th>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "      <td>Несомненно, для каждого мужчины в этом мире гд...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496059 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                                     Go.   \n",
       "1                                                     Go.   \n",
       "2                                                     Go.   \n",
       "3                                                     Hi.   \n",
       "4                                                     Hi.   \n",
       "...                                                   ...   \n",
       "496054  At a moment when our economy is growing, our b...   \n",
       "496055  When I was younger, I hated going to weddings....   \n",
       "496056  Since there are usually multiple websites on a...   \n",
       "496057  If someone who doesn't know your background sa...   \n",
       "496058  Doubtless there exists in this world precisely...   \n",
       "\n",
       "                                                      rus  \n",
       "0                                                   Марш!  \n",
       "1                                                    Иди.  \n",
       "2                                                  Идите.  \n",
       "3                                           Здравствуйте.  \n",
       "4                                                 Привет!  \n",
       "...                                                   ...  \n",
       "496054  В тот момент, когда наша экономика растёт, наш...  \n",
       "496055  Когда я была помоложе, я ненавидела ходить на ...  \n",
       "496056  Поскольку сайтов, посвящённых какой-либо теме,...  \n",
       "496057  Если кто-то незнакомый говорит, что вы говорит...  \n",
       "496058  Несомненно, для каждого мужчины в этом мире гд...  \n",
       "\n",
       "[496059 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "721551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "743dc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s,lang = 'eng'):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    if lang=='eng':\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    elif lang=='rus':\n",
    "        r = re.compile(r\"[^ЁёА-я.!?]+\")\n",
    "        r.sub(\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8d54677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(df, reverse=False):\n",
    "  \n",
    "    if reverse:\n",
    "        lang1 = df.columns[1]\n",
    "        lang2 = df.columns[0]\n",
    "    else:\n",
    "        lang1 = df.columns[0]\n",
    "        lang2 = df.columns[1]\n",
    "    \n",
    "    print(f\"Reading lines {lang1} to {lang2}...\")\n",
    "    \n",
    "    pairs = df.copy()\n",
    "    \n",
    "    pairs[lang1] = pairs[lang1].apply(lambda x: normalizeString(x,lang=lang1))\n",
    "    pairs[lang2] = pairs[lang2].apply(lambda x: normalizeString(x,lang=lang2))\n",
    "    \n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs[[lang1,lang2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f777377",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPairs(df):\n",
    "    lang1 = df.columns[0]\n",
    "    lang2 = df.columns[1]\n",
    "    return df[\n",
    "                     (df[lang1].str.split(\" \").map(len)<MAX_LENGTH) \n",
    "                   & (df[lang2].str.split(\" \").map(len)<MAX_LENGTH)\n",
    "                   & (df[lang2].str.startswith(eng_prefixes))\n",
    "                ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f90ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines rus to eng...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28727 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 10804\n",
      "eng 4306\n",
      "                       rus                   eng\n",
      "7368  мне как-то страшно .  i m kind of scared .\n"
     ]
    }
   ],
   "source": [
    "def prepareData(df, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(df, reverse=True)\n",
    "    print(\"Read %s sentence pairs\" % pairs.shape[0])\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % pairs.shape[0])\n",
    "    print(\"Counting words...\")\n",
    "    _ = pairs[pairs.columns[0]].apply(input_lang.addSentence)\n",
    "    _ = pairs[pairs.columns[1]].apply(output_lang.addSentence)\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(df,reverse=True)\n",
    "print(pairs.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164cb4f2",
   "metadata": {},
   "source": [
    "### Тренировочный и проверочные датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "fc75439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25855, 2), test_shape: (2872, 2)\n"
     ]
    }
   ],
   "source": [
    "#get train and test datasets\n",
    "testcoeff = 0.1\n",
    "test_pairs  = pairs.sample(int(pairs.shape[0]*testcoeff))\n",
    "train_pairs = pairs[~pairs.index.isin(test_pairs.index)].to_numpy()\n",
    "test_pairs = test_pairs.to_numpy()\n",
    "print(f'train shape: {train_pairs.shape}, test_shape: {test_pairs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "b453ef0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['мне девятнадцать лет .', 'i m .'],\n",
       "       ['со мнои все в порядке .', 'i m ok .'],\n",
       "       ['у меня все хорошо .', 'i m ok .'],\n",
       "       ...,\n",
       "       ['она проводит каждое воскресенье со своеи бабушкои .',\n",
       "        'she spends time with her grandmother every sunday .'],\n",
       "       ['после аварии она перестала бывать на людях .',\n",
       "        'she stopped appearing in public after her accident .'],\n",
       "       ['они ведут переговоры, чтобы приити к приемлемому компромиссу .',\n",
       "        'they are negotiating to reach a satisfactory compromise .']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c578a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbd1c0",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "135235fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,layer_num=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,num_layers=layer_num)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.layer_num, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc23d64",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8f7d60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,layer_num=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,num_layers=layer_num)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.layer_num, BATCH_SIZE, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "24a7f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bd777a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33afef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b5ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    #training_pairs = [tensorsFromPair(x) for x in train_pairs]\n",
    "    \n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21fbe850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7e50fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            \n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ee546ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a664b",
   "metadata": {},
   "source": [
    "### Тренируем без изменений моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7524f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 13m 46s) (5000 6%) 3.0999\n",
      "1m 49s (- 11m 53s) (10000 13%) 2.6345\n",
      "2m 40s (- 10m 43s) (15000 20%) 2.3529\n",
      "3m 32s (- 9m 43s) (20000 26%) 2.1575\n",
      "4m 23s (- 8m 47s) (25000 33%) 2.0192\n",
      "5m 14s (- 7m 52s) (30000 40%) 1.8629\n",
      "6m 6s (- 6m 58s) (35000 46%) 1.7465\n",
      "6m 57s (- 6m 5s) (40000 53%) 1.6711\n",
      "7m 49s (- 5m 12s) (45000 60%) 1.5388\n",
      "8m 41s (- 4m 20s) (50000 66%) 1.4955\n",
      "9m 33s (- 3m 28s) (55000 73%) 1.4233\n",
      "10m 24s (- 2m 36s) (60000 80%) 1.3349\n",
      "11m 16s (- 1m 44s) (65000 86%) 1.3045\n",
      "12m 8s (- 0m 52s) (70000 93%) 1.2223\n",
      "13m 0s (- 0m 0s) (75000 100%) 1.1790\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9c25a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> вы немного странныи .\n",
      "= you re a little weird .\n",
      "< you re a bit strange . <EOS>\n",
      "\n",
      "> у меня серьезные проблемы .\n",
      "= i am in deep water .\n",
      "< i m in trouble . . <EOS>\n",
      "\n",
      "> мы стоим перед трудным выбором .\n",
      "= we are faced with a difficult choice .\n",
      "< we are faced with our uncle . <EOS>\n",
      "\n",
      "> я до смерти боюсь пресмыкающихся .\n",
      "= i m deathly afraid of reptiles .\n",
      "< i m afraid of death . <EOS>\n",
      "\n",
      "> я рисковая .\n",
      "= i m adventurous .\n",
      "< i m an . <EOS>\n",
      "\n",
      "> вам сюда нельзя .\n",
      "= you re not allowed in here .\n",
      "< you re not allowed in . . <EOS>\n",
      "\n",
      "> ты замечательныи друг .\n",
      "= you re a wonderful friend .\n",
      "< you re an friend . <EOS>\n",
      "\n",
      "> вы все довольны .\n",
      "= you re all happy .\n",
      "< you re all right . <EOS>\n",
      "\n",
      "> я не вооружена .\n",
      "= i m unarmed .\n",
      "< i m not an . . <EOS>\n",
      "\n",
      "> я еще слишком молод для этого .\n",
      "= i m too young to do that yet .\n",
      "< i m too young to do this . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d55faf",
   "metadata": {},
   "source": [
    "### Добавим рекурентный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd7c5a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 5s (- 15m 11s) (5000 6%) 3.1344\n",
      "2m 2s (- 13m 19s) (10000 13%) 2.7124\n",
      "3m 1s (- 12m 6s) (15000 20%) 2.4445\n",
      "4m 0s (- 11m 1s) (20000 26%) 2.2477\n",
      "4m 59s (- 9m 59s) (25000 33%) 2.0614\n",
      "5m 59s (- 8m 58s) (30000 40%) 1.9540\n",
      "6m 58s (- 7m 58s) (35000 46%) 1.8326\n",
      "7m 57s (- 6m 57s) (40000 53%) 1.7264\n",
      "8m 56s (- 5m 57s) (45000 60%) 1.6329\n",
      "9m 55s (- 4m 57s) (50000 66%) 1.5137\n",
      "10m 53s (- 3m 57s) (55000 73%) 1.4571\n",
      "11m 52s (- 2m 58s) (60000 80%) 1.3684\n",
      "12m 51s (- 1m 58s) (65000 86%) 1.2925\n",
      "13m 50s (- 0m 59s) (70000 93%) 1.2558\n",
      "14m 50s (- 0m 0s) (75000 100%) 1.1885\n"
     ]
    }
   ],
   "source": [
    "layer_num = 2\n",
    "hidden_size = 256\n",
    "encoder2 = EncoderRNN(input_lang.n_words, hidden_size,layer_num).to(device)\n",
    "decoder2 = DecoderRNN(hidden_size, output_lang.n_words,layer_num).to(device)\n",
    "\n",
    "trainIters(encoder2, decoder2, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f7f4507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я читаю книгу об американскои истории .\n",
      "= i m reading a book on american history .\n",
      "< i m reading a book of a . . <EOS>\n",
      "\n",
      "> я немного смущен .\n",
      "= i m a bit confused .\n",
      "< i m a bit shy . <EOS>\n",
      "\n",
      "> мы ваша последняя надежда .\n",
      "= we re your last hope .\n",
      "< we re going to be your plan . <EOS>\n",
      "\n",
      "> рада тебя видеть, том .\n",
      "= i m glad to see you tom .\n",
      "< i m glad to you tom . <EOS>\n",
      "\n",
      "> вы постоянно ко мне придираетесь .\n",
      "= you re always finding fault with me .\n",
      "< you re always finding with me . <EOS>\n",
      "\n",
      "> я чувствую легкии голод .\n",
      "= i m getting a little hungry .\n",
      "< i m feeling feeling . <EOS>\n",
      "\n",
      "> мы сожалеем, что это произошло .\n",
      "= we re sorry that it happened .\n",
      "< we re sure that s happened . <EOS>\n",
      "\n",
      "> ты же не женат ?\n",
      "= you re single aren t you ?\n",
      "< you re not married are you ? ? ? <EOS>\n",
      "\n",
      "> красивая, правда ?\n",
      "= she s beautiful isn t she ?\n",
      "< i m dying about everything aren t ? ? <EOS>\n",
      "\n",
      "> я за ним .\n",
      "= i m behind him .\n",
      "< i m ready . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder2, decoder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d3330",
   "metadata": {},
   "source": [
    "### Заменим ячейку GRU на LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db18e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,layer_num=1):\n",
    "        super(EncoderRNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size,num_layers=layer_num)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.layer_num, BATCH_SIZE, self.hidden_size, device=device),\n",
    "                torch.zeros(self.layer_num, BATCH_SIZE, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf6a77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN2(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,layer_num=1):\n",
    "        super(DecoderRNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_num = layer_num\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size,num_layers=layer_num)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, BATCH_SIZE, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(self.layer_num, BATCH_SIZE, self.hidden_size, device=device),\n",
    "                torch.zeros(self.layer_num, BATCH_SIZE, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07ae4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 58s (- 13m 35s) (5000 6%) 3.2439\n",
      "1m 49s (- 11m 54s) (10000 13%) 2.7884\n",
      "2m 42s (- 10m 49s) (15000 20%) 2.5888\n",
      "3m 34s (- 9m 50s) (20000 26%) 2.3689\n",
      "4m 27s (- 8m 54s) (25000 33%) 2.2432\n",
      "5m 20s (- 8m 0s) (30000 40%) 2.0884\n",
      "6m 13s (- 7m 7s) (35000 46%) 1.9598\n",
      "7m 7s (- 6m 13s) (40000 53%) 1.8978\n",
      "8m 0s (- 5m 20s) (45000 60%) 1.7956\n",
      "8m 53s (- 4m 26s) (50000 66%) 1.7104\n",
      "9m 46s (- 3m 33s) (55000 73%) 1.6203\n",
      "10m 39s (- 2m 39s) (60000 80%) 1.5582\n",
      "11m 32s (- 1m 46s) (65000 86%) 1.4897\n",
      "12m 25s (- 0m 53s) (70000 93%) 1.4260\n",
      "13m 18s (- 0m 0s) (75000 100%) 1.3684\n"
     ]
    }
   ],
   "source": [
    "layer_num = 1\n",
    "hidden_size = 256\n",
    "encoder3 = EncoderRNN2(input_lang.n_words, hidden_size, layer_num).to(device)\n",
    "decoder3 = DecoderRNN2(hidden_size, output_lang.n_words, layer_num).to(device)\n",
    "\n",
    "trainIters(encoder3, decoder3, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac2a98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> успех ему обеспечен .\n",
      "= he is bound to succeed .\n",
      "< he is the . . . <EOS>\n",
      "\n",
      "> я счастливее вас .\n",
      "= i m happier than you .\n",
      "< i m older than you . <EOS>\n",
      "\n",
      "> я не говорю, что его музыка плохая .\n",
      "= i m not saying his music is bad .\n",
      "< i m not ashamed of what i . <EOS>\n",
      "\n",
      "> мне надоело слушать тома .\n",
      "= i m sick of listening to tom .\n",
      "< i m tired of tom s . . <EOS>\n",
      "\n",
      "> я пишу эссе .\n",
      "= i m writing an essay .\n",
      "< i m writing a letter . <EOS>\n",
      "\n",
      "> вы обе симпатичные .\n",
      "= you re both pretty .\n",
      "< you re both up . <EOS>\n",
      "\n",
      "> я жду своеи очереди .\n",
      "= i m waiting for my turn .\n",
      "< i m looking my my . . <EOS>\n",
      "\n",
      "> я худая .\n",
      "= i m thin .\n",
      "< i m an . <EOS>\n",
      "\n",
      "> я никчемен .\n",
      "= i m useless .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> ты опять тут .\n",
      "= you re back again .\n",
      "< you re back here . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder3, decoder3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7969b",
   "metadata": {},
   "source": [
    "### Добавим слой к LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d9b50f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 5s (- 15m 17s) (5000 6%) 3.3529\n",
      "2m 3s (- 13m 22s) (10000 13%) 2.8448\n",
      "3m 2s (- 12m 10s) (15000 20%) 2.6480\n",
      "4m 1s (- 11m 2s) (20000 26%) 2.4950\n",
      "5m 0s (- 10m 0s) (25000 33%) 2.3934\n",
      "5m 59s (- 8m 58s) (30000 40%) 2.2527\n",
      "6m 57s (- 7m 57s) (35000 46%) 2.1321\n",
      "7m 56s (- 6m 56s) (40000 53%) 2.0132\n",
      "8m 55s (- 5m 56s) (45000 60%) 1.9300\n",
      "9m 54s (- 4m 57s) (50000 66%) 1.8367\n",
      "10m 52s (- 3m 57s) (55000 73%) 1.7785\n",
      "11m 52s (- 2m 58s) (60000 80%) 1.6856\n",
      "12m 51s (- 1m 58s) (65000 86%) 1.6026\n",
      "13m 52s (- 0m 59s) (70000 93%) 1.5375\n",
      "15m 1s (- 0m 0s) (75000 100%) 1.4619\n"
     ]
    }
   ],
   "source": [
    "layer_num = 2\n",
    "hidden_size = 256\n",
    "encoder4 = EncoderRNN2(input_lang.n_words, hidden_size,layer_num).to(device)\n",
    "decoder4 = DecoderRNN2(hidden_size, output_lang.n_words,layer_num).to(device)\n",
    "\n",
    "trainIters(encoder4, decoder4, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a7ff1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> вы не туда идете .\n",
      "= you re going the wrong direction .\n",
      "< you re going to go there . <EOS>\n",
      "\n",
      "> я доволен тем, что сделал том .\n",
      "= i m happy with what tom did .\n",
      "< i m happy to see tom . . <EOS>\n",
      "\n",
      "> я заслуживаю доверия .\n",
      "= i m reliable .\n",
      "< i m the one who understands . <EOS>\n",
      "\n",
      "> я оставлю книги здесь .\n",
      "= i am leaving the books here .\n",
      "< i m going to go here . <EOS>\n",
      "\n",
      "> ты повыше меня .\n",
      "= you re a bit taller than i am .\n",
      "< you re a than me am . <EOS>\n",
      "\n",
      "> ты странныи парень .\n",
      "= you re a weird guy .\n",
      "< you re a strange person . <EOS>\n",
      "\n",
      "> у тебя носки надеты наизнанку .\n",
      "= you re wearing your socks inside out .\n",
      "< you re asking in good way . <EOS>\n",
      "\n",
      "> я здесь не для того, чтобы кому-то навредить .\n",
      "= i m not here to hurt anybody .\n",
      "< i m not the only one here . <EOS>\n",
      "\n",
      "> я просто шучу .\n",
      "= i m only joking .\n",
      "< i m just just . <EOS>\n",
      "\n",
      "> я привыкла сама себе готовить .\n",
      "= i m used to cooking for myself .\n",
      "< i m getting to french french . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder4, decoder4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68d945",
   "metadata": {},
   "source": [
    "ВЫВОДЫ: LSTM ячейки обучаются дольше, чем GRU, как и должно быть. \n",
    "Увеличение числа скрытых слоёв даёт худший результат на маленьком количестве итераций. \n",
    "Все методы показали достаточно неплохое качество переаода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e838722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cce2318",
   "metadata": {},
   "source": [
    "## *Обучение батчами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "676c5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "#функция преобразована для обучения на батчах\n",
    "def tensorFromSentence2(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    #indexes.append(EOS_token)\n",
    "    indexes = indexes + [EOS_token]*(MAX_LENGTH-len(indexes))\n",
    "    return np.array(indexes)\n",
    "#torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair2(pair):\n",
    "    input_tensor = tensorFromSentence2(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence2(output_lang, pair[1])\n",
    "    return np.array([input_tensor, target_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2d252dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_pairs = np.array([tensorsFromPair2(x) for x in train_pairs])\n",
    "test_pairs = np.array([tensorsFromPair2(x) for x in test_pairs])\n",
    "\n",
    "#train_pairs = train_pairs[np.argsort((train_pairs[:,1,:] == 1).sum(axis=1))]\n",
    "#test_pairs = test_pairs[np.argsort((test_pairs[:,1,:] == 1).sum(axis=1))]\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(train_pairs[:,0,:]).long(),torch.Tensor(train_pairs[:,1,:]).long())\n",
    "test_dataset = TensorDataset(torch.Tensor(test_pairs[:,0,:]).long(),torch.Tensor(test_pairs[:,1,:]).long())\n",
    "\n",
    "train_dl = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dl = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "7f9706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, epoch=10, print_every=100, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for ep in range(epoch):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        print_loss_total = 0  # Reset every print_every\n",
    "        plot_loss_total = 0  # Reset every plot_every\n",
    "        \n",
    "        for X, y in train_dl:\n",
    "            if X.shape[0] !=BATCH_SIZE:\n",
    "                    continue\n",
    "\n",
    "            input_tensor, target_tensor = X.to(device), y.to(device)\n",
    "            #input_tensor = training_pair[0]\n",
    "            #target_tensor = training_pair[1]\n",
    "            \n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            \n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "            \n",
    "\n",
    "        if ep % 1 == 0:\n",
    "            print_loss_avg = print_loss_total / train_iters\n",
    "            print_loss_total = 0 \n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, (ep+1) / epoch),\n",
    "                                             ep, ep / epoch * 100, print_loss_avg))\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "15366004",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    #ограничиваем длиной минимального предложения в батче, иначе модель, демонстрируя отличный loss на обучении\n",
    "    #на тестовых данных показывает какую то погоду\n",
    "    input_length = input_tensor.size(1) #max_length - (input_tensor == 1).sum(axis=1).max().item() + 1 \n",
    "    target_length = target_tensor.size(1) #max_length - (target_tensor == 1).sum(axis=1).max().item() + 1 \n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    #print(input_length)\n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[:,ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]*BATCH_SIZE], device=device).view(-1,1)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output.squeeze(), target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:,di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output,target_tensor[:,di])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    #print(loss)\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a2425a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 11s (- 5m 42s) (0 0%) 2.9880\n",
      "0m 23s (- 5m 28s) (1 3%) 2.5612\n",
      "0m 35s (- 5m 15s) (2 6%) 2.4301\n",
      "0m 46s (- 5m 2s) (3 10%) 2.3127\n",
      "0m 58s (- 4m 50s) (4 13%) 2.2680\n",
      "1m 9s (- 4m 38s) (5 16%) 2.2074\n",
      "1m 21s (- 4m 26s) (6 20%) 2.1379\n",
      "1m 32s (- 4m 15s) (7 23%) 2.0815\n",
      "1m 44s (- 4m 3s) (8 26%) 2.0319\n",
      "1m 55s (- 3m 51s) (9 30%) 1.9558\n",
      "2m 7s (- 3m 40s) (10 33%) 1.9238\n",
      "2m 19s (- 3m 29s) (11 36%) 1.8754\n",
      "2m 30s (- 3m 17s) (12 40%) 1.8397\n",
      "2m 42s (- 3m 5s) (13 43%) 1.8121\n",
      "2m 54s (- 2m 54s) (14 46%) 1.7873\n",
      "3m 5s (- 2m 42s) (15 50%) 1.7570\n",
      "3m 17s (- 2m 30s) (16 53%) 1.7340\n",
      "3m 28s (- 2m 19s) (17 56%) 1.6999\n",
      "3m 40s (- 2m 7s) (18 60%) 1.6637\n",
      "3m 52s (- 1m 56s) (19 63%) 1.6429\n",
      "4m 3s (- 1m 44s) (20 66%) 1.6116\n",
      "4m 15s (- 1m 32s) (21 70%) 1.5981\n",
      "4m 26s (- 1m 21s) (22 73%) 1.5702\n",
      "4m 38s (- 1m 9s) (23 76%) 1.5347\n",
      "4m 49s (- 0m 57s) (24 80%) 1.5249\n",
      "5m 1s (- 0m 46s) (25 83%) 1.4969\n",
      "5m 13s (- 0m 34s) (26 86%) 1.4848\n",
      "5m 24s (- 0m 23s) (27 90%) 1.4548\n",
      "5m 36s (- 0m 11s) (28 93%) 1.4303\n",
      "5m 47s (- 0m 0s) (29 96%) 1.4061\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "hidden_size = 256\n",
    "encoderB = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoderB = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoderB, decoderB, 30, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "b2024574",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "def evaluateB(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        #input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_tensor = torch.Tensor(sentence).long().to(device)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            #print(input_tensor[ei])\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "       \n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                #print(topi.item())\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "cb5333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomlyB(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(train_pairs)\n",
    "        print('>', ' '.join([input_lang.index2word[x] for x in pair[0]]))\n",
    "        print('=', ' '.join([output_lang.index2word[x] for x in pair[1]]))\n",
    "        output_words = evaluateB(encoderB, decoderB, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "65331168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> он боится делать ошибки . EOS EOS EOS EOS EOS\n",
      "= he s afraid of making mistakes . EOS EOS EOS\n",
      "< he is afraid to be a . . <EOS>\n",
      "\n",
      "> я не уверена . EOS EOS EOS EOS EOS EOS\n",
      "= i am not sure . EOS EOS EOS EOS EOS\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> нам будет вас не хватать . EOS EOS EOS EOS\n",
      "= we re going to miss you . EOS EOS EOS\n",
      "< we re going to miss you . <EOS>\n",
      "\n",
      "> я стоматолог . EOS EOS EOS EOS EOS EOS EOS\n",
      "= i m a dentist . EOS EOS EOS EOS EOS\n",
      "< i m a . <EOS>\n",
      "\n",
      "> он всегда опаздывает в школу . EOS EOS EOS EOS\n",
      "= he is always late for school . EOS EOS EOS\n",
      "< he is always in in the . <EOS>\n",
      "\n",
      "> вы не много теряете . EOS EOS EOS EOS EOS\n",
      "= you re not missing much . EOS EOS EOS EOS\n",
      "< you re not the wrong . <EOS>\n",
      "\n",
      "> я вправе иметь собственное мнение . EOS EOS EOS EOS\n",
      "= i m entitled to my own opinion . EOS EOS\n",
      "< i m a to to to the . . <EOS>\n",
      "\n",
      "> я благоразумен . EOS EOS EOS EOS EOS EOS EOS\n",
      "= i m prudent . EOS EOS EOS EOS EOS EOS\n",
      "< i m a . <EOS>\n",
      "\n",
      "> он здесь для того, чтобы защитить тебя . EOS EOS\n",
      "= he s here to protect you . EOS EOS EOS\n",
      "< he is here to see you . . <EOS>\n",
      "\n",
      "> на неи зеленое платье . EOS EOS EOS EOS EOS\n",
      "= she is wearing a green robe . EOS EOS EOS\n",
      "< she is a to the . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomlyB(encoder4, decoder4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea0552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
