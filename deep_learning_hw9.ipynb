{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7de8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ffce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\".\\rus-eng\\rus.txt\",sep='\\t',names=['eng','rus','c'],encoding='utf-8')[['eng','rus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c97f74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>rus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Марш!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Иди.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Идите.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Здравствуйте.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Привет!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496054</th>\n",
       "      <td>At a moment when our economy is growing, our b...</td>\n",
       "      <td>В тот момент, когда наша экономика растёт, наш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496055</th>\n",
       "      <td>When I was younger, I hated going to weddings....</td>\n",
       "      <td>Когда я была помоложе, я ненавидела ходить на ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496056</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Поскольку сайтов, посвящённых какой-либо теме,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496057</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Если кто-то незнакомый говорит, что вы говорит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496058</th>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "      <td>Несомненно, для каждого мужчины в этом мире гд...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496059 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                                     Go.   \n",
       "1                                                     Go.   \n",
       "2                                                     Go.   \n",
       "3                                                     Hi.   \n",
       "4                                                     Hi.   \n",
       "...                                                   ...   \n",
       "496054  At a moment when our economy is growing, our b...   \n",
       "496055  When I was younger, I hated going to weddings....   \n",
       "496056  Since there are usually multiple websites on a...   \n",
       "496057  If someone who doesn't know your background sa...   \n",
       "496058  Doubtless there exists in this world precisely...   \n",
       "\n",
       "                                                      rus  \n",
       "0                                                   Марш!  \n",
       "1                                                    Иди.  \n",
       "2                                                  Идите.  \n",
       "3                                           Здравствуйте.  \n",
       "4                                                 Привет!  \n",
       "...                                                   ...  \n",
       "496054  В тот момент, когда наша экономика растёт, наш...  \n",
       "496055  Когда я была помоложе, я ненавидела ходить на ...  \n",
       "496056  Поскольку сайтов, посвящённых какой-либо теме,...  \n",
       "496057  Если кто-то незнакомый говорит, что вы говорит...  \n",
       "496058  Несомненно, для каждого мужчины в этом мире гд...  \n",
       "\n",
       "[496059 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca892df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b422de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s,lang = 'eng'):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    if lang=='eng':\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    elif lang=='rus':\n",
    "        r = re.compile(r\"[^ЁёА-я.!?]+\")\n",
    "        r.sub(\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c526d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(df, reverse=False):\n",
    "  \n",
    "    if reverse:\n",
    "        lang1 = df.columns[1]\n",
    "        lang2 = df.columns[0]\n",
    "    else:\n",
    "        lang1 = df.columns[0]\n",
    "        lang2 = df.columns[1]\n",
    "    \n",
    "    print(f\"Reading lines {lang1} to {lang2}...\")\n",
    "    \n",
    "    pairs = df.copy()\n",
    "    \n",
    "    pairs[lang1] = pairs[lang1].apply(lambda x: normalizeString(x,lang=lang1))\n",
    "    pairs[lang2] = pairs[lang2].apply(lambda x: normalizeString(x,lang=lang2))\n",
    "    \n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs[[lang1,lang2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a6b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPairs(df):\n",
    "    lang1 = df.columns[0]\n",
    "    lang2 = df.columns[1]\n",
    "    return df[\n",
    "                     (df[lang1].str.split(\" \").map(len)<MAX_LENGTH) \n",
    "                   & (df[lang2].str.split(\" \").map(len)<MAX_LENGTH)\n",
    "                   & (df[lang2].str.startswith(eng_prefixes))\n",
    "                ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393fde09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines rus to eng...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28727 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 10804\n",
      "eng 4306\n",
      "                        rus                        eng\n",
      "14675  она не моя девушка .  she s not my girlfriend .\n"
     ]
    }
   ],
   "source": [
    "def prepareData(df, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(df, reverse=True)\n",
    "    print(\"Read %s sentence pairs\" % pairs.shape[0])\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % pairs.shape[0])\n",
    "    print(\"Counting words...\")\n",
    "    _ = pairs[pairs.columns[0]].apply(input_lang.addSentence)\n",
    "    _ = pairs[pairs.columns[1]].apply(output_lang.addSentence)\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(df,reverse=True)\n",
    "print(pairs.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2d267",
   "metadata": {},
   "source": [
    "### Тренировочный и проверочные датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09ae975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25855, 2), test_shape: (2872, 2)\n"
     ]
    }
   ],
   "source": [
    "#get train and test datasets\n",
    "testcoeff = 0.1\n",
    "test_pairs  = pairs.sample(int(pairs.shape[0]*testcoeff))\n",
    "train_pairs = pairs[~pairs.index.isin(test_pairs.index)].to_numpy()\n",
    "test_pairs = test_pairs.to_numpy()\n",
    "print(f'train shape: {train_pairs.shape}, test_shape: {test_pairs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bceecf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['мне девятнадцать лет .', 'i m .'],\n",
       "       ['со мнои все в порядке .', 'i m ok .'],\n",
       "       ['у меня все хорошо .', 'i m ok .'],\n",
       "       ...,\n",
       "       ['она улыбнулась в ответ на его нежныи взгляд .',\n",
       "        'she smiled in response to his affectionate glance .'],\n",
       "       ['каждую субботу после обеда она играет в теннис .',\n",
       "        'she spends every saturday afternoon playing tennis .'],\n",
       "       ['после аварии она перестала бывать на людях .',\n",
       "        'she stopped appearing in public after her accident .']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ac125",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f79e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa009654",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1be395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa21047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf90fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3693b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d9d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12d0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5643444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        #print(sentence.shape)\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c932384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "756a373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 29s (- 20m 56s) (5000 6%) 3.1064\n",
      "2m 49s (- 18m 20s) (10000 13%) 2.6007\n",
      "4m 9s (- 16m 36s) (15000 20%) 2.3511\n",
      "5m 29s (- 15m 4s) (20000 26%) 2.1200\n",
      "6m 46s (- 13m 33s) (25000 33%) 1.9889\n",
      "8m 4s (- 12m 6s) (30000 40%) 1.8606\n",
      "9m 20s (- 10m 40s) (35000 46%) 1.7633\n",
      "10m 37s (- 9m 17s) (40000 53%) 1.6643\n",
      "11m 53s (- 7m 55s) (45000 60%) 1.5774\n",
      "13m 9s (- 6m 34s) (50000 66%) 1.5083\n",
      "14m 26s (- 5m 14s) (55000 73%) 1.4422\n",
      "15m 42s (- 3m 55s) (60000 80%) 1.3883\n",
      "16m 59s (- 2m 36s) (65000 86%) 1.3421\n",
      "18m 15s (- 1m 18s) (70000 93%) 1.2798\n",
      "19m 32s (- 0m 0s) (75000 100%) 1.2624\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b176f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я готов идти за вами .\n",
      "= i m ready to follow you .\n",
      "< i am ready to follow you . <EOS>\n",
      "\n",
      "> я в этом уверен .\n",
      "= i m certain of it .\n",
      "< i m absolutely sure of it . <EOS>\n",
      "\n",
      "> я сеичас иду в отель .\n",
      "= i m going to the hotel now .\n",
      "< i m going to the in now . <EOS>\n",
      "\n",
      "> они пытаются помочь .\n",
      "= they re trying to help .\n",
      "< they re trying to help . <EOS>\n",
      "\n",
      "> они работают наверху .\n",
      "= they re working upstairs .\n",
      "< they re working on . <EOS>\n",
      "\n",
      "> я просто болтаюсь .\n",
      "= i m just hanging out .\n",
      "< i m just a . . <EOS>\n",
      "\n",
      "> они сумасшедшие .\n",
      "= they re crazy .\n",
      "< they re crazy . <EOS>\n",
      "\n",
      "> мы недалеко от дома тома .\n",
      "= we re not far from tom s .\n",
      "< we re behind of tom . <EOS>\n",
      "\n",
      "> вы гении .\n",
      "= you re a genius .\n",
      "< you re a genius . <EOS>\n",
      "\n",
      "> я об этом не думаю .\n",
      "= i m not thinking about it .\n",
      "< i m not going about it . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904a898",
   "metadata": {},
   "source": [
    "### На основе скалярного произведения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a6bd50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_DOT(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN_DOT, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn_weights = F.softmax(\n",
    "            torch.matmul(\n",
    "                encoder_outputs,hidden[0].squeeze()* self.hidden_size**-0.5\n",
    "                ).unsqueeze(0)\n",
    "            , dim=1)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7bd800b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 18s (- 18m 23s) (5000 6%) 3.0899\n",
      "2m 31s (- 16m 27s) (10000 13%) 2.6058\n",
      "3m 45s (- 15m 1s) (15000 20%) 2.3548\n",
      "4m 58s (- 13m 41s) (20000 26%) 2.1562\n",
      "6m 12s (- 12m 25s) (25000 33%) 2.0032\n",
      "7m 27s (- 11m 10s) (30000 40%) 1.8859\n",
      "8m 42s (- 9m 56s) (35000 46%) 1.7555\n",
      "9m 56s (- 8m 41s) (40000 53%) 1.6533\n",
      "11m 11s (- 7m 27s) (45000 60%) 1.5728\n",
      "12m 26s (- 6m 13s) (50000 66%) 1.5008\n",
      "13m 40s (- 4m 58s) (55000 73%) 1.4226\n",
      "14m 56s (- 3m 44s) (60000 80%) 1.3417\n",
      "16m 10s (- 2m 29s) (65000 86%) 1.3002\n",
      "17m 25s (- 1m 14s) (70000 93%) 1.2211\n",
      "18m 42s (- 0m 0s) (75000 100%) 1.1754\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN_DOT(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d8d79d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ты в этом уверена, да ?\n",
      "= you re sure about this right ?\n",
      "< you re not that around aren t you ? <EOS>\n",
      "\n",
      "> он в пути .\n",
      "= he s on his way .\n",
      "< he is on the way . <EOS>\n",
      "\n",
      "> она темнокожая .\n",
      "= she is dark skinned .\n",
      "< she is young . <EOS>\n",
      "\n",
      "> мы избегаем тома .\n",
      "= we re avoiding tom .\n",
      "< we re going to wait for tom . <EOS>\n",
      "\n",
      "> я очень рассеянная .\n",
      "= i m very absent minded .\n",
      "< i m very grateful . <EOS>\n",
      "\n",
      "> рад за вас обоих .\n",
      "= i m happy for both of you .\n",
      "< i m glad to see you . <EOS>\n",
      "\n",
      "> он очень робкии .\n",
      "= he s very timid .\n",
      "< he s very shy . <EOS>\n",
      "\n",
      "> простите, что утром опоздал .\n",
      "= i m sorry i was late this morning .\n",
      "< i m sorry i m late . <EOS>\n",
      "\n",
      "> не уверен, что это случится .\n",
      "= i m not sure that that ll happen .\n",
      "< i m not sure this is is . . <EOS>\n",
      "\n",
      "> я выигрываю .\n",
      "= i m winning .\n",
      "< i m a . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08dc6c",
   "metadata": {},
   "source": [
    "### На основе MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "40c78854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_MLP(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN_MLP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        #self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.mlp =  nn.Sequential(\n",
    "                    nn.Linear(self.hidden_size*2, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, self.max_length)\n",
    "                    )\n",
    "        \n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "       \n",
    "        attn_weights = F.softmax(\n",
    "            self.mlp(\n",
    "                torch.cat(\n",
    "                        (encoder_outputs,hidden[0].repeat(self.max_length,1)), dim=1\n",
    "                    )\n",
    "                ).mean(dim=1).unsqueeze(0),\n",
    "        #     self.mlp((encoder_outputs+hidden[0]).flatten().unsqueeze(0)),\n",
    "        #    #self.mlp(torch.cat((encoder_outputs,hidden[0].repeat(self.max_length,1)), dim=1).flatten(0).unsqueeze(0)).mean(dim=1).unsqueeze(0),\n",
    "        #    #self.mlp(encoder_outputs).mean(dim=1).unsqueeze(0),\n",
    "        #    #self.mlp(encoder_outputs.flatten(0).unsqueeze(0))\n",
    "            dim=1\n",
    "            )\n",
    "        #attn_weights = self.mlp((encoder_outputs*hidden[0]).flatten().unsqueeze(0)),\n",
    "\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "59e0e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 40s (- 23m 22s) (5000 6%) 3.0996\n",
      "3m 15s (- 21m 9s) (10000 13%) 2.6038\n",
      "4m 51s (- 19m 26s) (15000 20%) 2.3760\n",
      "6m 27s (- 17m 46s) (20000 26%) 2.1552\n",
      "8m 4s (- 16m 8s) (25000 33%) 1.9992\n",
      "9m 42s (- 14m 33s) (30000 40%) 1.8598\n",
      "11m 20s (- 12m 57s) (35000 46%) 1.7277\n",
      "12m 58s (- 11m 21s) (40000 53%) 1.6295\n",
      "14m 36s (- 9m 44s) (45000 60%) 1.5684\n",
      "16m 13s (- 8m 6s) (50000 66%) 1.4648\n",
      "17m 49s (- 6m 29s) (55000 73%) 1.4120\n",
      "19m 24s (- 4m 51s) (60000 80%) 1.3247\n",
      "21m 0s (- 3m 13s) (65000 86%) 1.2607\n",
      "22m 36s (- 1m 36s) (70000 93%) 1.2144\n",
      "24m 13s (- 0m 0s) (75000 100%) 1.1692\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN_MLP(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9dde2b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> у меня все еще немного кружится голова .\n",
      "= i m still a little woozy .\n",
      "< i m still a little sick . <EOS>\n",
      "\n",
      "> я просто счастлив, что все так хорошо закончилось .\n",
      "= i m just happy it ended so well .\n",
      "< i m just doing that that s is . <EOS>\n",
      "\n",
      "> я счастлив тратить деньги на книги .\n",
      "= i am happy to spend money on books .\n",
      "< i m three inches my life in . . <EOS>\n",
      "\n",
      "> вы еще молодая .\n",
      "= you re still young .\n",
      "< you re still young . <EOS>\n",
      "\n",
      "> он так же силен, как всегда .\n",
      "= he is as strong as ever .\n",
      "< he s as smart as ever . <EOS>\n",
      "\n",
      "> я собираюсь покинуть страну .\n",
      "= i m going to leave the country .\n",
      "< i m going to leave my . . <EOS>\n",
      "\n",
      "> я все еще в австралии .\n",
      "= i m still in australia .\n",
      "< i m still in australia . <EOS>\n",
      "\n",
      "> ты права .\n",
      "= you re right .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> я подвыпившая .\n",
      "= i m tipsy .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> я смущен .\n",
      "= i m confused .\n",
      "< i m embarrassed . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26419cd",
   "metadata": {},
   "source": [
    "Применение Scoring Function на основе скалярного произведения и с использованием MLP, немного уменьшило ошибку, \n",
    "однако совсем не драматично. На тестовых данных, вроде как работает получше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0750e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
